{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Protein Interaction Network\n",
    "\n",
    "Machine learning classification task for predicting whether a protein pair interacts or not\n",
    "\n",
    "Protein pairs are generated from a test pathogen against human proteins contained in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import itertools\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from Bio import SearchIO\n",
    "\n",
    "from features import domain_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "dir_in = os.path.join(parent_dir, 'data')\n",
    "dir_out = os.path.join(parent_dir, 'data', 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain pathogen protein domains\n",
    "\n",
    "Pathogen: *Streptococcus pneumoniae* strain D39 (**STRP2**)\n",
    "\n",
    "Protein sequence source: https://www.uniprot.org\n",
    "\n",
    "- `Organism [OS]: Streptococcus pneumoniae serotype 2 (strain D39 / NCTC 7466) [373153]`\n",
    "- `Sequence length: From 50`\n",
    "\n",
    "Extraction of Pfam domains: `hmmscan`\n",
    "- `hmmscan --tblout STRP2_pfam_hits --acc --noali -E 0.00001 --domE 0.00001 --cpu 7 ~/hmmer-3.2.1/pfam/Pfam-A.hmm STRP2_sequences.fasta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pfam data from the training pathogens\n",
    "pfam_dict, pfam_set = joblib.load('pfam.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1643 STRP2 proteins for HP-PPI prediction\n"
     ]
    }
   ],
   "source": [
    "# Parse hmmscan result of STRP2\n",
    "f_in = os.path.join(dir_in, 'STRP2_pfam_hits')\n",
    "pathogen_prots = [] # store Uniprot accessions of STRP2\n",
    "\n",
    "for query in SearchIO.parse(f_in, 'hmmer3-tab'):\n",
    "    uniprot_id = query.id.split('|')[1]\n",
    "    domains = []\n",
    "    \n",
    "    # Read each domain hits in query\n",
    "    for hit in query.hits:\n",
    "        pfam_acc = hit.accession.split('.')[0] # Pfam accession of domain\n",
    "        \n",
    "        # Select only domains that exists in the training set\n",
    "        if pfam_acc in pfam_set: \n",
    "            domains.append(pfam_acc)\n",
    "        \n",
    "    # Add the pathogen protein to an existing domains dict\n",
    "    pfam_dict[uniprot_id] = domains \n",
    "    pathogen_prots.append(uniprot_id)\n",
    "\n",
    "# Print statistics\n",
    "print('Selected %i STRP2 proteins for HP-PPI prediction' % len(pathogen_prots))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate candidate protein pairs and extract domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained 3188 human proteins\n"
     ]
    }
   ],
   "source": [
    "# Extract human proteins from training dataset\n",
    "f_in = os.path.join(dir_in, 'positive_pairs.tsv')\n",
    "\n",
    "human_prots = set(pd.read_csv(f_in, sep='\\t')['Human_Uniprot_ID'])\n",
    "print('Obtained %i human proteins' % len(human_prots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5237884 protein pairs for prediction\n"
     ]
    }
   ],
   "source": [
    "# Generate protein pairs\n",
    "pairs = [pair for pair in itertools.product(pathogen_prots, human_prots)]\n",
    "print('Generated %i protein pairs for prediction' % len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<2x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sparse.csc_matrix([1,0,2,0,0])\n",
    "b = sparse.csr_matrix([0,4,0,1,1])\n",
    "a\n",
    "sparse.vstack([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14808/5237884 [00:28<2:35:56, 558.24it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9e5fa2e3678d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/HP-PPI-prediction/codes/features.py\u001b[0m in \u001b[0;36mdomain_features\u001b[0;34m(protein, domain_dict, domain_set)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mdomain_profile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain_profile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14808/5237884 [00:40<2:35:56, 558.24it/s]"
     ]
    }
   ],
   "source": [
    "# Set up feature extraction function\n",
    "feature_function = partial(domain_features,\n",
    "                           domain_dict=pfam_dict,\n",
    "                           domain_set=pfam_set)\n",
    "\n",
    "# Extract features for all pairs\n",
    "X = []\n",
    "\n",
    "for pair in tqdm(pairs):\n",
    "    features = sum(map(feature_function, pair))\n",
    "    X.append(features)\n",
    "\n",
    "# Save features as a sparse matrix\n",
    "X = sparse.vstack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 0.6460189731717099,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 0.717391365308206,\n",
       " 'gamma': 0.5220571710711481,\n",
       " 'learning_rate': 0.38181251415891027,\n",
       " 'max_delta_step': 6,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 0,\n",
       " 'missing': nan,\n",
       " 'n_estimators': 1000,\n",
       " 'n_jobs': -1,\n",
       " 'nthread': None,\n",
       " 'objective': 'binary:logistic',\n",
       " 'random_state': 47,\n",
       " 'reg_alpha': 0.001947442553211054,\n",
       " 'reg_lambda': 1.706103927414546,\n",
       " 'scale_pos_weight': 1.5261481450511425,\n",
       " 'seed': None,\n",
       " 'silent': None,\n",
       " 'subsample': 0.6077746823368507,\n",
       " 'verbosity': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = joblib.load('best_model.pkl')\n",
    "clf.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
